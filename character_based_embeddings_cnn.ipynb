{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An illustration of character-based embedding lookup using convolution layer\n",
    "\n",
    "In many NLP tasks word are resolved to embedding vectors, via an embedding layer. The embedding layer may be initialized with pre-trained word vectors such as word2vec or may be randomly initialized and learnt during training.\n",
    "\n",
    "In this illustration, word embedding vectors are composed from character-level embeddings, instead of a simple lookup. The process is as follows.\n",
    "After pre-processing sentences to ensure all sentences and words are of equal length.\n",
    "1. For each word, lookup embeddings for each character of the word\n",
    "2. Apply 1-D convolution layer to each word\n",
    "3. Apply max pooling to get concise feature representation, which will serve as the word's embedding\n",
    "\n",
    "Computed word embeddings can be fed into larger, deeper networks for NLP tasks such as NMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ipython_utils import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Character indices"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'a': 26, 'b': 27, 'c': 28, 'd': 29, 'e': 30, 'f': 31, 'g': 32, 'h': 33, 'i': 34, 'j': 35, 'k': 36, 'l': 37, 'm': 38, 'n': 39, 'o': 40, 'p': 41, 'q': 42, 'r': 43, 's': 44, 't': 45, 'u': 46, 'v': 47, 'w': 48, 'x': 49, 'y': 50, 'z': 51, '0': 52, '1': 53, '2': 54, '3': 55, '4': 56, '5': 57, '6': 58, '7': 59, '8': 60, '9': 61, '<pad>': 62, '<unk>': 63}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Random batch of sentences"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "|Sentence | # words|\n",
       "|--|--|\n",
       "| Programming is fun | 3 |\n",
       "| Pluto, Makemake, and Ceres are dwarf planets | 7 |\n",
       "| To be or not to be | 6 |\n",
       "| Light at the end of the tunnel. | 7 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "|Sentence | Sentence with word indices|\n",
       "|--|--|\n",
       "| Programming is fun | [[15, 43, 40, 32, 43, 26, 38, 38, 34, 39, 32, 62, 62, 62, 62], [34, 44, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [31, 46, 39, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62]] |\n",
       "| Pluto, Makemake, and Ceres are dwarf planets | [[15, 37, 46, 45, 40, 63, 62, 62, 62, 62, 62, 62, 62, 62, 62], [12, 26, 36, 30, 38, 26, 36, 30, 63, 62, 62, 62, 62, 62, 62], [26, 39, 29, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [2, 30, 43, 30, 44, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [26, 43, 30, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [29, 48, 26, 43, 31, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [41, 37, 26, 39, 30, 45, 44, 62, 62, 62, 62, 62, 62, 62, 62]] |\n",
       "| To be or not to be | [[19, 40, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [27, 30, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [40, 43, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [39, 40, 45, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [45, 40, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [27, 30, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62]] |\n",
       "| Light at the end of the tunnel. | [[11, 34, 32, 33, 45, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [26, 45, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [45, 33, 30, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [30, 39, 29, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [40, 31, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [45, 33, 30, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [45, 46, 39, 39, 30, 37, 63, 62, 62, 62, 62, 62, 62, 62, 62]] |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Sentence batch as a tensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[15, 43, 40, 32, 43, 26, 38, 38, 34, 39, 32, 62, 62, 62, 62],\n",
      "         [34, 44, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [31, 46, 39, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62]],\n",
      "\n",
      "        [[15, 37, 46, 45, 40, 63, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [12, 26, 36, 30, 38, 26, 36, 30, 63, 62, 62, 62, 62, 62, 62],\n",
      "         [26, 39, 29, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [ 2, 30, 43, 30, 44, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [26, 43, 30, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [29, 48, 26, 43, 31, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [41, 37, 26, 39, 30, 45, 44, 62, 62, 62, 62, 62, 62, 62, 62]],\n",
      "\n",
      "        [[19, 40, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [27, 30, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [40, 43, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [39, 40, 45, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [45, 40, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [27, 30, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62]],\n",
      "\n",
      "        [[11, 34, 32, 33, 45, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [26, 45, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [45, 33, 30, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [30, 39, 29, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [40, 31, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [45, 33, 30, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62],\n",
      "         [45, 46, 39, 39, 30, 37, 63, 62, 62, 62, 62, 62, 62, 62, 62]]])\n",
      "Shape = torch.Size([4, 7, 15])\n"
     ]
    }
   ],
   "source": [
    "# constants/hyperparameters\n",
    "BATCH_SIZE = 4\n",
    "# MAX_WORD_LEN is used to ensure all words are of same length; pad/truncate shorter/longer words respectively\n",
    "MAX_WORD_LEN = 15\n",
    "CHAR_EMBED_SIZE = 5\n",
    "CONV_1D_KERNEL_SIZE = 4\n",
    "CONV_1D_OUTPUT_FILTERS = 5\n",
    "\n",
    "# Setup miniaturized dataset for the purpose of illustration\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "\n",
    "# dictionary to lookup an index given a character\n",
    "char2index = {ch: i for i, ch in enumerate(alphabet)}\n",
    "\n",
    "# add <pad> and <unk> token for padding and out-of-alphabet characters\n",
    "char2index['<pad>'] = len(char2index)\n",
    "char2index['<unk>'] = len(char2index)\n",
    "\n",
    "# define constants for padding and unk characters\n",
    "PAD_TOKEN = char2index['<pad>']\n",
    "UNK_TOKEN = char2index['<unk>']\n",
    "\n",
    "print_h4('Character indices')\n",
    "print(char2index)\n",
    "\n",
    "# few sentences\n",
    "sents_lang = [\n",
    "    'To be or not to be',\n",
    "    'Programming is fun',\n",
    "    'Light at the end of the tunnel.',\n",
    "    'Aurora Borealis is indeed a spectacle!',\n",
    "    'Mercury, Venus, Earth and Mars are rocky planets',\n",
    "    'Jupiter and Saturn are gas giants',\n",
    "    'Uranus and Neptune are ice giants',\n",
    "    'Pluto, Makemake, and Ceres are dwarf planets'\n",
    "]\n",
    "\n",
    "# strip out leading/trailing whitespaces, if any\n",
    "sents_lang = [sent.strip() for sent in sents_lang]\n",
    "\n",
    "# select a random batch of sentences\n",
    "random.shuffle(sents_lang)\n",
    "sents_lang_batch = sents_lang[0:BATCH_SIZE]\n",
    "\n",
    "print_h4('Random batch of sentences')\n",
    "print_table(['Sentence', '# words'], [(sent, len(sent.split())) for sent in sents_lang_batch])\n",
    "\n",
    "# convert sentences to a list of list of words\n",
    "sents_lang_batch_words = [sent.split() for sent in sents_lang_batch]\n",
    "\n",
    "# convert each word to an array of indices\n",
    "sent_batch = [[[char2index.get(ch, UNK_TOKEN) for ch in word] for word in sent] for sent in sents_lang_batch_words]\n",
    "\n",
    "# now make sure all sentences are of the same length and in each sentence, make sure all \n",
    "# words are of the same length. insert <pad> characters where necessary\n",
    "max_sent_len = max(len(sent) for sent in sent_batch)\n",
    "for s in range(len(sent_batch)):\n",
    "    sent = sent_batch[s]\n",
    "    for w in range(len(sent)):\n",
    "        # pad/truncate each word as necessary\n",
    "        if len(sent[w]) < MAX_WORD_LEN:\n",
    "            # pad\n",
    "            sent[w].extend([PAD_TOKEN]*(MAX_WORD_LEN - len(sent[w])))\n",
    "        elif len(sent[w]) > MAX_WORD_LEN:\n",
    "            # truncate\n",
    "            sent[w] = sent[w][0:MAX_WORD_LEN]\n",
    "\n",
    "    # pad sentence with extra words to ensure all sentences are of same length\n",
    "    if len(sent) < max_sent_len:\n",
    "        sent.extend([[PAD_TOKEN]*MAX_WORD_LEN]*(max_sent_len-len(sent)))\n",
    "\n",
    "print_table(['Sentence', 'Sentence with word indices'], zip(sents_lang, sent_batch))\n",
    "\n",
    "# validate to ensure correct sizes\n",
    "for sent in sent_batch:\n",
    "    assert len(sent) == max_sent_len\n",
    "    for word in sent:\n",
    "        assert len(word) == MAX_WORD_LEN\n",
    "\n",
    "# finally convert the sentence batch into a tensor\n",
    "input_batch = torch.tensor(sent_batch)\n",
    "\n",
    "print_h4('Sentence batch as a tensor')\n",
    "print(input_batch)\n",
    "print('Shape = {}'.format(input_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a convolution layer to compute word embeddings\n",
    "class CharBasedCNN(nn.Module):\n",
    "    def __init__(self, char_embed_size, n_char_embeddings, \n",
    "                 conv_output_channels, conv_kernel_size,\n",
    "                 use_maxpool_1d=False):\n",
    "        \"\"\"\n",
    "        char_embed_size: size of character embedding vector (hyperparameter)\n",
    "        n_char_embeddings: no.of character embeddings = no.of chars in the alphabet + 2 (<pad> & <unk>)\n",
    "        conv_output_channels: no.of output channels from convolution layer (hyperparameter)\n",
    "        conv_kernel_size: convolution kernel size (hyperparameter)\n",
    "        use_maxpool_1d: only used to compare nn.MaxPool1d and torch.max \n",
    "        \"\"\"\n",
    "        super(CharBasedCNN, self).__init__()\n",
    "        self.use_maxpool_1d = use_maxpool_1d\n",
    "        self.embedding = nn.Embedding(num_embeddings=n_char_embeddings, \n",
    "                                      embedding_dim=char_embed_size)\n",
    "        self.conv1d = nn.Conv1d(in_channels=char_embed_size, out_channels=conv_output_channels, \n",
    "                                kernel_size=conv_kernel_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Input is a tensor of dimension (batch_size, sentence_length, word_length)\n",
    "        batch_size = no.of sentences in the batch\n",
    "        sentence_length = no.of words in the sentence\n",
    "        word_length = no.of chars in the word\n",
    "        \"\"\"\n",
    "        print('input shape = {}'.format(input.shape))\n",
    "        \n",
    "        # lookup character embeddings\n",
    "        # shape after resolving embeddings will be a 4-d tensor of shape\n",
    "        # (batch_size, sentence_length, word_length, CHAR_EMBED_SIZE)\n",
    "        # CHAR_EMBED_SIZE is a hyperparameter defined above, it defines character embedding vector size\n",
    "        input_char_embed_4d = self.embedding(input)\n",
    "        print('char embeded input 4d shape = {}'.format(input_char_embed_4d.shape))\n",
    "        \n",
    "        # Input to nn.Conv1d must be a 3d tensor\n",
    "        # merge 1st 2 dimensions into a single dimension\n",
    "        # resulting tensor is a 3-d tensor of shape\n",
    "        # (word_count, word_length, CHAR_EMBED_SIZE)\n",
    "        # word_count = batch_size * sentence_length\n",
    "        input_char_embed_3d = input_char_embed_4d.view((input_char_embed_4d.shape[0]*input_char_embed_4d.shape[1],\n",
    "                                                        input_char_embed_4d.shape[2], input_char_embed_4d.shape[3]))\n",
    "        print('char embeded input 3d shape = {}'.format(input_char_embed_3d.shape))\n",
    "\n",
    "        # nn.Conv1d convolves along the last dimension\n",
    "        # We need the convolution to run on characters of a word -- the 2nd dimension\n",
    "        # Transpose the tensor to get it into required shape\n",
    "        conv_input = input_char_embed_3d.transpose(dim0=1, dim1=2)\n",
    "        print('conv1d input shape = {}'.format(conv_input.shape))\n",
    "\n",
    "        conv_out = self.conv1d(conv_input)\n",
    "        F.relu_(conv_out)\n",
    "        print('conv1d output shape = {}'.format(conv_out.shape))\n",
    "        \n",
    "        if self.use_maxpool_1d:\n",
    "            max_1d = nn.MaxPool1d(kernel_size=conv_out.shape[-1], stride=1)\n",
    "            maxpool_out = max_1d(conv_out)\n",
    "            print('maxpool out shape = {}'.format(maxpool_out.shape))\n",
    "\n",
    "            maxpool_out = maxpool_out.squeeze()\n",
    "            print('maxpool out squeeze shape = {}'.format(maxpool_out.shape))\n",
    "        else:\n",
    "            maxpool_out, _ = conv_out.max(dim=2)\n",
    "            print('maxpool out shape = {}'.format(maxpool_out.shape))\n",
    "\n",
    "        maxpool_out_reshape = maxpool_out.view(input_char_embed_4d.shape[0], input_char_embed_4d.shape[1], -1)\n",
    "        print('maxpool out final shape = {}\\n'.format(maxpool_out_reshape.shape))\n",
    "\n",
    "        return maxpool_out_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Computing embeddings. Using torch.max() instead of nn.MaxPool1d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape = torch.Size([4, 7, 15])\n",
      "char embeded input 4d shape = torch.Size([4, 7, 15, 5])\n",
      "char embeded input 3d shape = torch.Size([28, 15, 5])\n",
      "conv1d input shape = torch.Size([28, 5, 15])\n",
      "conv1d output shape = torch.Size([28, 5, 12])\n",
      "maxpool out shape = torch.Size([28, 5])\n",
      "maxpool out final shape = torch.Size([4, 7, 5])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Computing embeddings. Using nn.MaxPool1d instead of torch.max()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape = torch.Size([4, 7, 15])\n",
      "char embeded input 4d shape = torch.Size([4, 7, 15, 5])\n",
      "char embeded input 3d shape = torch.Size([28, 15, 5])\n",
      "conv1d input shape = torch.Size([28, 5, 15])\n",
      "conv1d output shape = torch.Size([28, 5, 12])\n",
      "maxpool out shape = torch.Size([28, 5, 1])\n",
      "maxpool out squeeze shape = torch.Size([28, 5])\n",
      "maxpool out final shape = torch.Size([4, 7, 5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ch_cnn = CharBasedCNN(CHAR_EMBED_SIZE, len(char2index), CONV_1D_OUTPUT_FILTERS, CONV_1D_KERNEL_SIZE)\n",
    "print_h4('Computing embeddings. Using torch.max() instead of nn.MaxPool1d')\n",
    "embeddings_1 = ch_cnn(input_batch)\n",
    "\n",
    "print_h4('Computing embeddings. Using nn.MaxPool1d instead of torch.max()')\n",
    "ch_cnn.use_maxpool_1d = True\n",
    "embeddings_2 = ch_cnn(input_batch)\n",
    "\n",
    "# both ways of computing embeddings must produce same values\n",
    "assert (embeddings_1 == embeddings_2).all()\n",
    "\n",
    "# further validate to ensure convolutions applied to individual sentences produce\n",
    "# same result as when applied to batch\n",
    "# validate to ensure convolutions are applied correctly\n",
    "for i, sent in enumerate(input_batch):\n",
    "    sent_char_embed = ch_cnn.embedding(sent)\n",
    "    # transpose before applying conv1d\n",
    "    sent_char_embed = sent_char_embed.transpose(dim0=1, dim1=2)\n",
    "    # apply convolution\n",
    "    sent_conv_out = ch_cnn.conv1d(sent_char_embed)\n",
    "    F.relu_(sent_conv_out)\n",
    "    sent_conv_out, _ = sent_conv_out.max(dim=2)\n",
    "    assert (embeddings_1[i] == sent_conv_out).all() and (embeddings_2[i] == sent_conv_out).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
